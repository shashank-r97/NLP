{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AishJo/Repository1/blob/master/LSTM_Glove_Category.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "buklJs6mdj5T",
    "outputId": "0856779a-6cc7-403e-8da4-03b5a2e4f0ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vvLHOmMukGGN"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Pxdph9JB-dG"
   },
   "outputs": [],
   "source": [
    "#!pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OZMWoVO4kknG"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model, Sequential \n",
    "from keras.layers import Input, Masking\n",
    "from keras.layers import Dense, Input, Reshape\n",
    "from keras.layers import Dropout, Activation\n",
    "from keras.layers import Dense, GlobalAveragePooling1D, Activation\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM, SimpleRNN\n",
    "from keras.layers import Embedding\n",
    "import keras.backend as K \n",
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models.phrases import Phraser, Phrases\n",
    "import re \n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "1J88vxQgkvZY",
    "outputId": "4058a64e-f58c-4033-b1c0-7424b23ebe5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 369 ms, sys: 27.8 ms, total: 397 ms\n",
      "Wall time: 428 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# reading the data\n",
    "df = pd.read_csv('/content/drive/Shared drives/DSO 560 NLP Project/data.csv')\n",
    "# creating a subset of the relevant attribute name and then dropping the column\n",
    "df = df[df['attribute_name'] == 'category'].drop(columns = ['attribute_name'])\n",
    "# combining similar category attribute values and removing spaces\n",
    "df['attribute_value'] = df['attribute_value'].apply(lambda x: 'sweatshirthoodie' if x == 'sweatshirt hoodie' else x)\n",
    "df['attribute_value'] = df['attribute_value'].apply(lambda x: 'blazerscoatsjackets' if x == 'blazer , coat jacket' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 569
    },
    "colab_type": "code",
    "id": "vyu18_culshy",
    "outputId": "c9dd8c3c-d380-453e-b3a8-a306dc6327e2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>brand</th>\n",
       "      <th>product_full_name</th>\n",
       "      <th>description</th>\n",
       "      <th>brand_category</th>\n",
       "      <th>attribute_value</th>\n",
       "      <th>details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01DVCVGDJQC4J8JJ35PKZ4J169</td>\n",
       "      <td>loewe</td>\n",
       "      <td>hammock small textured leather shoulder bag</td>\n",
       "      <td>black textured leather calf hook fasten open w...</td>\n",
       "      <td>bag tote bag tote bag</td>\n",
       "      <td>accessory</td>\n",
       "      <td>item 's measurement depth 14 cm height 23 cm m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>01DPGSTG4M1RXB26QMMN0MPPB8</td>\n",
       "      <td>j crew</td>\n",
       "      <td>mockneck sweater supersoft yarn</td>\n",
       "      <td>cozy flattering mockneck sweater feel good loo...</td>\n",
       "      <td>sweater</td>\n",
       "      <td>sweater</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>01E2KKRH99SZ1PTR2E2ABVYJ5S</td>\n",
       "      <td>alo</td>\n",
       "      <td>vapor high waist legging</td>\n",
       "      <td>signature lift fabric moisture wicking technol...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>xxs 00 0 , xs 0 2 , s 4 6 , m 8 10 , l 12 14 ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>01E2M1MYJ1FYVHG2AMXHDMNQSP</td>\n",
       "      <td>alo</td>\n",
       "      <td>prism high waist capris</td>\n",
       "      <td>high waistband help flat figure moisture wicki...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>xxs 00 , xs 0 2 , s 4 6 , m 8 10 , l 12 14 hig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>01E2KZ8BZF6M1XCHBZGEX3AF78</td>\n",
       "      <td>alo</td>\n",
       "      <td>cover tank</td>\n",
       "      <td>hard earn abs supersoft faux wrap tank 's crop...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>xxs 00 0 , xs 0 2 , s 4 6 , m 8 10 , l 12 14 ,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    product_id  ...                                            details\n",
       "3   01DVCVGDJQC4J8JJ35PKZ4J169  ...  item 's measurement depth 14 cm height 23 cm m...\n",
       "32  01DPGSTG4M1RXB26QMMN0MPPB8  ...                                                NaN\n",
       "36  01E2KKRH99SZ1PTR2E2ABVYJ5S  ...  xxs 00 0 , xs 0 2 , s 4 6 , m 8 10 , l 12 14 ,...\n",
       "50  01E2M1MYJ1FYVHG2AMXHDMNQSP  ...  xxs 00 , xs 0 2 , s 4 6 , m 8 10 , l 12 14 hig...\n",
       "52  01E2KZ8BZF6M1XCHBZGEX3AF78  ...  xxs 00 0 , xs 0 2 , s 4 6 , m 8 10 , l 12 14 ,...\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4KCfa3CVn9nY"
   },
   "outputs": [],
   "source": [
    "# creating a feature combining brand, productname, description and brand category\n",
    "df['text'] = (df['brand'] + ' ' + df['product_full_name'] + ' ' + df['description'] + ' ' + df['brand_category']).apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WMi2ULgelhFo"
   },
   "outputs": [],
   "source": [
    "# the predictor 'text' is assigned to 'X' and the 'attribute_value' t 'y'\n",
    "X = df['text'].values\n",
    "# one-hot-encoding the y variable\n",
    "y = pd.get_dummies(df['attribute_value'])\n",
    "label_list = y.columns\n",
    "y = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0YFmF01NwQGo"
   },
   "outputs": [],
   "source": [
    "# creating a function to create uni-grams and tokenizing data\n",
    "def encode_1gram(X, mode = 'binary'):\n",
    "    tokenizer = Tokenizer(num_words=500)\n",
    "    tokenizer.fit_on_texts(X)\n",
    "    length = max([len(s.split()) for s in df['text']])\n",
    "    X = tokenizer.texts_to_matrix(X, mode)\n",
    "    X = pad_sequences(X, maxlen=length, padding='post')\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "    return X, length, vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5oETme721eAP"
   },
   "outputs": [],
   "source": [
    "# creating a function to create bi-grams and tokenizing data\n",
    "def encode_2gram(X, mode='binary'):\n",
    "    phrases = Phrases(X, min_count=30)\n",
    "    bigrams = Phraser(phrases)\n",
    "    X = list(bigrams[X])\n",
    "\n",
    "    tokenizer = Tokenizer(num_words=500)\n",
    "    tokenizer.fit_on_texts(X)\n",
    "    length = max([len(s.split()) for s in df['text']])\n",
    "    X = tokenizer.texts_to_matrix(X, mode)\n",
    "    X = pad_sequences(X, maxlen=length, padding='post')\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "    return X, length, vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "30eS_YrlwyL9"
   },
   "outputs": [],
   "source": [
    "#Tokenizer.texts_to_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6oEaE9mamM7X"
   },
   "outputs": [],
   "source": [
    "# creating tf-idf vectors from uni-gram encoding\n",
    "X1, length1, vocab_size1 = encode_1gram(X, mode = 'tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YGFzNuUUxWmZ"
   },
   "outputs": [],
   "source": [
    "# creating tf-idf vectors from bi-gram encoding\n",
    "X2, length2, vocab_size2 = encode_2gram(X, mode = 'tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JM7aXsN--SXZ"
   },
   "outputs": [],
   "source": [
    "#X1 = X1.reshape(-1, 155, 1)\n",
    "#X2 = X2.reshape(-1, 155, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5626,
     "status": "ok",
     "timestamp": 1588653301525,
     "user": {
      "displayName": "Jasleen Kaur Ahuja",
      "photoUrl": "",
      "userId": "16363827072704495669"
     },
     "user_tz": 420
    },
    "id": "hJpzT_ygA7Pw",
    "outputId": "efd91098-2db1-48ee-a10a-d8fe8f709f2e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9975, 199)"
      ]
     },
     "execution_count": 73,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yf8Gl0NGA1HV"
   },
   "outputs": [],
   "source": [
    "# concatenating uni-gram and bi-gram\n",
    "X = np.concatenate([X1, X2], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ae88zjZ9CZye"
   },
   "outputs": [],
   "source": [
    "# splitting data into training and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VDwRtJkSBvxp"
   },
   "outputs": [],
   "source": [
    "# balancing the sample sets as the proportion of labels is unbalanced\n",
    "resampler = SMOTETomek(sampling_strategy = 'auto')\n",
    "X_train, y_train = resampler.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XNTeR6ZRoxcL"
   },
   "outputs": [],
   "source": [
    "num_classes = y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-xgZ_gpen5wR"
   },
   "outputs": [],
   "source": [
    "# defining LSTM model with sigmoid activation functions for prediction\n",
    "def define_model():\n",
    "    inputs = Input(shape=(length1+length2,))\n",
    "    #x1 = Conv1D(filters=num_classes, kernel_size=1, padding='valid')(inputs1)\n",
    "    embedding = Embedding(input_dim=vocab_size1, output_dim=100)(inputs)\n",
    "\n",
    "    #inputs2 = Input(shape=(length2,))\n",
    "    #x2 = Conv1D(filters=num_classes, kernel_size=1, padding='valid')(inputs2)\n",
    "    #dense2 = Dense(100, activation='relu')(inputs2)\n",
    "    #embedding2 = Embedding(input_dim=vocab_size2, output_dim=100)(inputs2)\n",
    "\n",
    "    #merged = concatenate([inputs1, inputs1])\n",
    "    x = LSTM(16, return_sequences=True, dropout=0.2, recurrent_dropout=0.15)(embedding)\n",
    "\n",
    "    #x = Dense(100, activation = 'relu')(inputs)\n",
    "\n",
    "\n",
    "    x = Conv1D(filters=num_classes, kernel_size=1, padding='valid')(x)\n",
    "    x = Conv1D(filters=num_classes, kernel_size=length1+length2, padding='valid')(x)\n",
    "    x = Reshape((num_classes,))(x)\n",
    "    #x = Dense(num_classes)(x)\n",
    "    out = Activation('sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs = [inputs], outputs = out)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 398
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 182848,
     "status": "ok",
     "timestamp": 1588653482690,
     "user": {
      "displayName": "Jasleen Kaur Ahuja",
      "photoUrl": "",
      "userId": "16363827072704495669"
     },
     "user_tz": 420
    },
    "id": "WtVkDeU4pOFw",
    "outputId": "118a6092-5f86-4046-b54e-154a29caf6cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 398)               0         \n",
      "_________________________________________________________________\n",
      "embedding_3 (Embedding)      (None, 398, 100)          595700    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 398, 16)           7488      \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 398, 7)            119       \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 1, 7)              19509     \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 7)                 0         \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 622,816\n",
      "Trainable params: 622,816\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = define_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 453
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 438807,
     "status": "ok",
     "timestamp": 1588653739334,
     "user": {
      "displayName": "Jasleen Kaur Ahuja",
      "photoUrl": "",
      "userId": "16363827072704495669"
     },
     "user_tz": 420
    },
    "id": "wfeN4H1XpRvM",
    "outputId": "458e2b68-bd77-4dd9-eb26-ac685a51e13e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17039 samples, validate on 4260 samples\n",
      "Epoch 1/10\n",
      "17039/17039 [==============================] - 26s 2ms/step - loss: 0.4310 - accuracy: 0.8470 - val_loss: 0.7176 - val_accuracy: 0.8571\n",
      "Epoch 2/10\n",
      "17039/17039 [==============================] - 26s 2ms/step - loss: 0.3909 - accuracy: 0.8571 - val_loss: 0.7612 - val_accuracy: 0.8571\n",
      "Epoch 3/10\n",
      "17039/17039 [==============================] - 26s 1ms/step - loss: 0.3894 - accuracy: 0.8571 - val_loss: 0.7385 - val_accuracy: 0.8571\n",
      "Epoch 4/10\n",
      "17039/17039 [==============================] - 25s 1ms/step - loss: 0.3877 - accuracy: 0.8571 - val_loss: 0.7345 - val_accuracy: 0.8571\n",
      "Epoch 5/10\n",
      "17039/17039 [==============================] - 25s 1ms/step - loss: 0.3817 - accuracy: 0.8571 - val_loss: 0.7210 - val_accuracy: 0.8571\n",
      "Epoch 6/10\n",
      "17039/17039 [==============================] - 26s 1ms/step - loss: 0.3703 - accuracy: 0.8567 - val_loss: 0.7189 - val_accuracy: 0.8530\n",
      "Epoch 7/10\n",
      "17039/17039 [==============================] - 26s 2ms/step - loss: 0.3633 - accuracy: 0.8572 - val_loss: 0.7236 - val_accuracy: 0.8514\n",
      "Epoch 8/10\n",
      "17039/17039 [==============================] - 25s 1ms/step - loss: 0.3569 - accuracy: 0.8580 - val_loss: 0.7443 - val_accuracy: 0.8406\n",
      "Epoch 9/10\n",
      "17039/17039 [==============================] - 26s 2ms/step - loss: 0.3512 - accuracy: 0.8596 - val_loss: 0.7539 - val_accuracy: 0.8372\n",
      "Epoch 10/10\n",
      "17039/17039 [==============================] - 25s 1ms/step - loss: 0.3451 - accuracy: 0.8611 - val_loss: 0.7646 - val_accuracy: 0.8330\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f7489394588>"
      ]
     },
     "execution_count": 80,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting data onto model\n",
    "model.fit(X_train, y_train, validation_split=0.2, epochs=10, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 440067,
     "status": "ok",
     "timestamp": 1588653741194,
     "user": {
      "displayName": "Jasleen Kaur Ahuja",
      "photoUrl": "",
      "userId": "16363827072704495669"
     },
     "user_tz": 420
    },
    "id": "RH0rgY1WChE4",
    "outputId": "85455148-6350-4487-c907-b16ac19d50b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "998/998 [==============================] - 2s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3710651554779443, 0.8541370034217834]"
      ]
     },
     "execution_count": 81,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluating model\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "58YGb44Ln1sL"
   },
   "outputs": [],
   "source": [
    "# probability of predicting each class for various records\n",
    "results = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C6FgcHherHja"
   },
   "outputs": [],
   "source": [
    "#Creating a DataFrame for the results\n",
    "results_df = pd.DataFrame()\n",
    "results_mask = results > 0.1\n",
    "for i in range(len(label_list)):\n",
    "    results_df[label_list[i]] = results_mask[:,i]\n",
    "    results_df[label_list[i]] = results_df[label_list[i]].apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 456225,
     "status": "ok",
     "timestamp": 1588653759037,
     "user": {
      "displayName": "Jasleen Kaur Ahuja",
      "photoUrl": "",
      "userId": "16363827072704495669"
     },
     "user_tz": 420
    },
    "id": "YpNDlwRQsFj5",
    "outputId": "ada860b7-fd84-436e-f78f-d839f4529c74"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 84,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df['sum']  = 0\n",
    "for key in label_list:\n",
    "    results_df['sum'] = results_df['sum'] + results_df[key]\n",
    "(results_df['sum'] == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 455700,
     "status": "ok",
     "timestamp": 1588653759038,
     "user": {
      "displayName": "Jasleen Kaur Ahuja",
      "photoUrl": "",
      "userId": "16363827072704495669"
     },
     "user_tz": 420
    },
    "id": "5WsQqrmxprsc",
    "outputId": "42bfd095-b26f-4080-c017-8103b4c232cc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coldweather</th>\n",
       "      <th>daytonight</th>\n",
       "      <th>nightout</th>\n",
       "      <th>vacation</th>\n",
       "      <th>weekend</th>\n",
       "      <th>work</th>\n",
       "      <th>workout</th>\n",
       "      <th>attribute_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>daytonight</td>\n",
       "      <td>nightout</td>\n",
       "      <td></td>\n",
       "      <td>weekend</td>\n",
       "      <td>work</td>\n",
       "      <td></td>\n",
       "      <td>daytonight, nightout, weekend, work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>coldweather</td>\n",
       "      <td>daytonight</td>\n",
       "      <td>nightout</td>\n",
       "      <td>vacation</td>\n",
       "      <td>weekend</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>coldweather, daytonight, nightout, vacation, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>coldweather</td>\n",
       "      <td>daytonight</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>weekend</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>coldweather, daytonight, weekend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>coldweather</td>\n",
       "      <td>daytonight</td>\n",
       "      <td>nightout</td>\n",
       "      <td>vacation</td>\n",
       "      <td>weekend</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>coldweather, daytonight, nightout, vacation, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>coldweather</td>\n",
       "      <td>daytonight</td>\n",
       "      <td>nightout</td>\n",
       "      <td>vacation</td>\n",
       "      <td>weekend</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>coldweather, daytonight, nightout, vacation, w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   coldweather  ...                                    attribute_value\n",
       "0               ...                daytonight, nightout, weekend, work\n",
       "1  coldweather  ...  coldweather, daytonight, nightout, vacation, w...\n",
       "2  coldweather  ...                   coldweather, daytonight, weekend\n",
       "3  coldweather  ...  coldweather, daytonight, nightout, vacation, w...\n",
       "4  coldweather  ...  coldweather, daytonight, nightout, vacation, w...\n",
       "\n",
       "[5 rows x 8 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = results_df.drop(columns = ['sum'])\n",
    "for key in label_list:\n",
    "    results_df[key] = results_df[key].apply(lambda x: key if x == 1 else '')\n",
    "\n",
    "results_df['attribute_value'] = ''\n",
    "for key in label_list:\n",
    "    results_df['attribute_value'] = results_df['attribute_value'] + ' ' + results_df[key]\n",
    "\n",
    "results_df['attribute_value'] = results_df['attribute_value'].apply(lambda x: ', '.join(x.split()))\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 502
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 455193,
     "status": "ok",
     "timestamp": 1588653759038,
     "user": {
      "displayName": "Jasleen Kaur Ahuja",
      "photoUrl": "",
      "userId": "16363827072704495669"
     },
     "user_tz": 420
    },
    "id": "BmfNQQbrqhhc",
    "outputId": "40882ea2-0aaa-4916-ed6c-9107f8b9a923"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "coldweather, daytonight, nightout, vacation, weekend          2744\n",
       "daytonight, nightout, weekend, work                           1881\n",
       "daytonight, nightout, weekend                                 1222\n",
       "daytonight, nightout, vacation, weekend                        751\n",
       "daytonight, nightout, vacation, weekend, work                  543\n",
       "daytonight, weekend, work                                      492\n",
       "daytonight, vacation, weekend                                  488\n",
       "daytonight, weekend                                            362\n",
       "coldweather, daytonight, nightout, weekend, work               326\n",
       "coldweather, daytonight, nightout, vacation, weekend, work     295\n",
       "coldweather, daytonight, weekend, work                         235\n",
       "coldweather, daytonight, nightout, weekend                     232\n",
       "daytonight, vacation, weekend, work                            216\n",
       "coldweather, daytonight, weekend                                68\n",
       "daytonight, weekend, work, workout                              23\n",
       "coldweather, daytonight, vacation, weekend                      22\n",
       "coldweather, weekend, work                                      18\n",
       "coldweather, daytonight, vacation, weekend, work                18\n",
       "daytonight, weekend, workout                                    10\n",
       "coldweather, daytonight, weekend, work, workout                  6\n",
       "coldweather, daytonight, weekend, workout                        5\n",
       "daytonight, nightout, weekend, workout                           5\n",
       "coldweather, weekend                                             4\n",
       "coldweather, vacation, weekend                                   3\n",
       "daytonight, nightout, vacation                                   3\n",
       "coldweather, weekend, workout                                    2\n",
       "daytonight, nightout, weekend, work, workout                     1\n",
       "Name: attribute_value, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df['attribute_value'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0YFmF01NwQGo"
   },
   "outputs": [],
   "source": [
    "# tokenizing the data and integer encoding it\n",
    "tokenizer = Tokenizer(num_words=5000, oov_token=\"UNKNOWN_TOKEN\")\n",
    "tokenizer.fit_on_texts(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5oETme721eAP"
   },
   "outputs": [],
   "source": [
    "# running the tokenizer function on features\n",
    "X = tokenizer.texts_to_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_IMFmGLi6sUH"
   },
   "outputs": [],
   "source": [
    "# getting vocab size and length for input\n",
    "length = max([len(s.split()) for s in df['text']])\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jHn0BxkM6zbH"
   },
   "outputs": [],
   "source": [
    "# padding the data to make it same size (max size)\n",
    "X = pad_sequences(X, maxlen=length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ae88zjZ9CZye"
   },
   "outputs": [],
   "source": [
    "# splitting training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "id": "VDwRtJkSBvxp",
    "outputId": "182043da-b9ec-45ae-847d-3ebdd235e8a5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# balancing the dataset to account for disproportionate of labels\n",
    "resampler = SMOTETomek(sampling_strategy = 'auto')\n",
    "X_train, y_train = resampler.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XNTeR6ZRoxcL"
   },
   "outputs": [],
   "source": [
    "num_classes = y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "8F-6edne7CKl",
    "outputId": "d1b084d6-9839-4826-edb5-b8d64bad1dfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# using glove vector to create function that makes word emebeddings\n",
    "def load_glove_vectors():\n",
    "    embeddings_index = {}\n",
    "    with open('/content/drive/Shared drives/DSO 560 NLP Project/glove.6B.100d.txt') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "    print('Loaded %s word vectors.' % len(embeddings_index))\n",
    "    return embeddings_index\n",
    "\n",
    "\n",
    "embeddings_index = load_glove_vectors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cm2saCqq7B6t"
   },
   "outputs": [],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = np.zeros((vocab_size, 100))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: # check that it is an actual word that we have embeddings for\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GcWVkLPD7Bq6"
   },
   "outputs": [],
   "source": [
    "# creating an LSTM model\n",
    "def define_model():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=length, trainable=False))\n",
    "    model.add(Masking(mask_value=0.0)) # masking layer, masks any words that don't have an embedding as 0s.\n",
    "    model.add(LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.15, activation = 'relu'))\n",
    "    model.add(LSTM(64, return_sequences=False, dropout=0.2, recurrent_dropout=0.15, activation = 'relu'))\n",
    "    #model.add(Flatten())\n",
    "    model.add(Dense(16, activation = 'relu'))\n",
    "    model.add(Dense(num_classes, activation='sigmoid'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RwR86N_D8RPY"
   },
   "source": [
    "def define_model():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=length, trainable=False))\n",
    "    #model.add(Masking(mask_value=0.0)) # masking layer, masks any words that don't have an embedding as 0s.\n",
    "    LSTM(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.15, activation = 'relu')\n",
    "    LSTM(128, return_sequences=False, dropout=0.2, recurrent_dropout=0.15, activation = 'relu')\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(16, activation = 'relu'))\n",
    "    model.add(Dense(num_classes, activation='sigmoid'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "colab_type": "code",
    "id": "WtVkDeU4pOFw",
    "outputId": "2a5041a1-dc57-46ed-ba48-39569ea8ea7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 155, 100)          615100    \n",
      "_________________________________________________________________\n",
      "masking_2 (Masking)          (None, 155, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 155, 64)           42240     \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 7)                 119       \n",
      "=================================================================\n",
      "Total params: 691,523\n",
      "Trainable params: 76,423\n",
      "Non-trainable params: 615,100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = define_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "wfeN4H1XpRvM",
    "outputId": "4c215e2b-4c5d-44ba-c1a2-8c0c73324ad0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11055 samples, validate on 2764 samples\n",
      "Epoch 1/10\n",
      "11055/11055 [==============================] - 19s 2ms/step - loss: 0.6397 - accuracy: 0.7459 - val_loss: 0.6130 - val_accuracy: 0.8571\n",
      "Epoch 2/10\n",
      "11055/11055 [==============================] - 17s 1ms/step - loss: 0.5865 - accuracy: 0.8569 - val_loss: 0.5567 - val_accuracy: 0.8571\n",
      "Epoch 3/10\n",
      "11055/11055 [==============================] - 16s 1ms/step - loss: 0.5079 - accuracy: 0.8571 - val_loss: 0.5308 - val_accuracy: 0.8571\n",
      "Epoch 4/10\n",
      "11055/11055 [==============================] - 16s 1ms/step - loss: 2.7004 - accuracy: 0.8567 - val_loss: 81.4542 - val_accuracy: 0.8536\n",
      "Epoch 5/10\n",
      "11055/11055 [==============================] - 16s 1ms/step - loss: 31.0084 - accuracy: 0.8385 - val_loss: 63.6311 - val_accuracy: 0.8239\n",
      "Epoch 6/10\n",
      "11055/11055 [==============================] - 16s 1ms/step - loss: 233410.5102 - accuracy: 0.8111 - val_loss: 5623585.1751 - val_accuracy: 0.7582\n",
      "Epoch 7/10\n",
      "11055/11055 [==============================] - 16s 1ms/step - loss: 3223003705.4781 - accuracy: 0.7883 - val_loss: 92342419.2880 - val_accuracy: 0.7283\n",
      "Epoch 8/10\n",
      "11055/11055 [==============================] - 16s 1ms/step - loss: 219246686.9295 - accuracy: 0.7756 - val_loss: 142309877.4182 - val_accuracy: 0.7143\n",
      "Epoch 9/10\n",
      "11055/11055 [==============================] - 16s 1ms/step - loss: 270193703412.6844 - accuracy: 0.7650 - val_loss: 96282766.0781 - val_accuracy: 0.7153\n",
      "Epoch 10/10\n",
      "11055/11055 [==============================] - 16s 1ms/step - loss: 37704691.9339 - accuracy: 0.7648 - val_loss: 137930346.8365 - val_accuracy: 0.7149\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f8cfc35fda0>"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting model on training data\n",
    "model.fit(X_train, y_train, validation_split=0.2, epochs=10, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "RH0rgY1WChE4",
    "outputId": "8ef60a8f-a97b-486b-8c68-ea1f67611982"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420/420 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6990222726549421, 0.42414966225624084]"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluating model\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ythmDKKlpjsc"
   },
   "outputs": [],
   "source": [
    "# making predictions\n",
    "results = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xjn1GCho_snJ"
   },
   "outputs": [],
   "source": [
    "# defining a threshold for prediction\n",
    "results_df = pd.DataFrame()\n",
    "results_mask = results > 0.5\n",
    "for i in range(len(label_list)):\n",
    "    results_df[label_list[i]] = results_mask[:,i]\n",
    "    results_df[label_list[i]] = results_df[label_list[i]].apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "5WsQqrmxprsc",
    "outputId": "879174c9-2d87-4911-e63c-ddff0813a44f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df['sum']  = 0\n",
    "for key in label_list:\n",
    "    results_df['sum'] = results_df['sum'] + results_df[key]\n",
    "(results_df['sum'] == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "BmfNQQbrqhhc",
    "outputId": "6dcca099-416f-4bc9-cb49-6660b4837f81"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accessory</th>\n",
       "      <th>blazerscoatsjackets</th>\n",
       "      <th>onepiece</th>\n",
       "      <th>piece</th>\n",
       "      <th>shoe</th>\n",
       "      <th>sweater</th>\n",
       "      <th>sweatshirthoodie</th>\n",
       "      <th>attribute_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accessory</td>\n",
       "      <td>blazerscoatsjackets</td>\n",
       "      <td></td>\n",
       "      <td>piece</td>\n",
       "      <td></td>\n",
       "      <td>sweater</td>\n",
       "      <td></td>\n",
       "      <td>accessory, blazerscoatsjackets, piece, sweater</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>accessory</td>\n",
       "      <td>blazerscoatsjackets</td>\n",
       "      <td></td>\n",
       "      <td>piece</td>\n",
       "      <td></td>\n",
       "      <td>sweater</td>\n",
       "      <td>sweatshirthoodie</td>\n",
       "      <td>accessory, blazerscoatsjackets, piece, sweater...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>accessory</td>\n",
       "      <td>blazerscoatsjackets</td>\n",
       "      <td></td>\n",
       "      <td>piece</td>\n",
       "      <td></td>\n",
       "      <td>sweater</td>\n",
       "      <td></td>\n",
       "      <td>accessory, blazerscoatsjackets, piece, sweater</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>accessory</td>\n",
       "      <td>blazerscoatsjackets</td>\n",
       "      <td></td>\n",
       "      <td>piece</td>\n",
       "      <td></td>\n",
       "      <td>sweater</td>\n",
       "      <td></td>\n",
       "      <td>accessory, blazerscoatsjackets, piece, sweater</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>accessory</td>\n",
       "      <td>blazerscoatsjackets</td>\n",
       "      <td></td>\n",
       "      <td>piece</td>\n",
       "      <td></td>\n",
       "      <td>sweater</td>\n",
       "      <td></td>\n",
       "      <td>accessory, blazerscoatsjackets, piece, sweater</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accessory  ...                                    attribute_value\n",
       "0  accessory  ...     accessory, blazerscoatsjackets, piece, sweater\n",
       "1  accessory  ...  accessory, blazerscoatsjackets, piece, sweater...\n",
       "2  accessory  ...     accessory, blazerscoatsjackets, piece, sweater\n",
       "3  accessory  ...     accessory, blazerscoatsjackets, piece, sweater\n",
       "4  accessory  ...     accessory, blazerscoatsjackets, piece, sweater\n",
       "\n",
       "[5 rows x 8 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = results_df.drop(columns = ['sum'])\n",
    "for key in label_list:\n",
    "    results_df[key] = results_df[key].apply(lambda x: key if x == 1 else '')\n",
    "\n",
    "results_df['attribute_value'] = ''\n",
    "for key in label_list:\n",
    "    results_df['attribute_value'] = results_df['attribute_value'] + ' ' + results_df[key]\n",
    "\n",
    "results_df['attribute_value'] = results_df['attribute_value'].apply(lambda x: ', '.join(x.split()))\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503
    },
    "colab_type": "code",
    "id": "kBsLjXEzyvys",
    "outputId": "bc72169d-68ff-4f1a-897c-574305fd71eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accessory, blazerscoatsjackets, piece, sweater                                      2048\n",
       "accessory, piece, shoe, sweatshirthoodie                                             606\n",
       "accessory, piece, sweater                                                            457\n",
       "accessory, blazerscoatsjackets, piece, sweater, sweatshirthoodie                     327\n",
       "accessory, blazerscoatsjackets, piece                                                194\n",
       "accessory, blazerscoatsjackets, sweater                                              111\n",
       "accessory, blazerscoatsjackets, piece, sweatshirthoodie                               95\n",
       "accessory, blazerscoatsjackets, sweater, sweatshirthoodie                             74\n",
       "accessory, blazerscoatsjackets, piece, shoe, sweater, sweatshirthoodie                59\n",
       "accessory, piece, sweater, sweatshirthoodie                                           49\n",
       "accessory, blazerscoatsjackets                                                        37\n",
       "accessory, piece                                                                      24\n",
       "accessory, blazerscoatsjackets, piece, shoe, sweatshirthoodie                         23\n",
       "accessory, sweater                                                                    19\n",
       "accessory, blazerscoatsjackets, sweatshirthoodie                                      19\n",
       "accessory, blazerscoatsjackets, shoe, sweater, sweatshirthoodie                        8\n",
       "accessory, piece, sweatshirthoodie                                                     8\n",
       "accessory, sweater, sweatshirthoodie                                                   8\n",
       "accessory, blazerscoatsjackets, shoe, sweatshirthoodie                                 7\n",
       "accessory, blazerscoatsjackets, onepiece, piece, shoe, sweater, sweatshirthoodie       6\n",
       "accessory, blazerscoatsjackets, onepiece, piece, sweater, sweatshirthoodie             5\n",
       "accessory, blazerscoatsjackets, piece, shoe, sweater                                   4\n",
       "accessory                                                                              2\n",
       "accessory, piece, shoe, sweater, sweatshirthoodie                                      1\n",
       "accessory, blazerscoatsjackets, shoe                                                   1\n",
       "accessory, blazerscoatsjackets, shoe, sweater                                          1\n",
       "accessory, blazerscoatsjackets, onepiece, piece, shoe, sweatshirthoodie                1\n",
       "Name: attribute_value, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df['attribute_value'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C8G0Q1SjfeQv"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('model.pickle', 'wb') as handle:\n",
    "    pickle.dump(model, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TZFAGD_chS6z"
   },
   "outputs": [],
   "source": [
    "def get_style(brand, product_full_name, description, details, brand_category):\n",
    "    def clean_text(x):\n",
    "        try:\n",
    "            x = re.sub(r'<.*?>', '',x)\n",
    "            x = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", x)\n",
    "            x = re.sub(r\"\\'s\", \" \\'s\", x)\n",
    "            x = re.sub(r\"\\'ve\", \" \\'ve\", x)\n",
    "            x = re.sub(r\"n\\'t\", \" n\\'t\", x)\n",
    "            x = re.sub(r\"\\'re\", \" \\'re\", x)\n",
    "            x = re.sub(r\"\\'d\", \" \\'d\", x)\n",
    "            x = re.sub(r\"\\'ll\", \" \\'ll\", x)\n",
    "            x = re.sub(r\",\", \" , \", x)\n",
    "            x = re.sub(r\"!\", \" ! \", x)\n",
    "            x = re.sub(r\"\\(\", \"\", x)\n",
    "            x = re.sub(r\"\\)\", \"\", x)\n",
    "            x = re.sub(r\"\\?\", \"\", x)\n",
    "            x = re.sub(r\"/\", \"\", x)\n",
    "            x = re.sub(r\"\\s{2,}\", \" \", x)\n",
    "            return x.lower()\n",
    "        except:\n",
    "            return ''\n",
    "\n",
    "    def lemmatizer(x):\n",
    "        return ' '.join([token.lemma_ for token in nlp(x)])\n",
    "        \n",
    "    with open('tokenizer.pickle', 'rb') as handle:\n",
    "        tokenizer = pickle.load(handle)\n",
    "    with open('model.pickle', 'rb') as handle:\n",
    "        model = pickle.load(handle)\n",
    "\n",
    "    data = pd.DataFrame({'brand':brand,'product_full_name':product_full_name,'description':description,'details':details,'brand_category':brand_category},index=[0]) \n",
    "    df = data.copy()\n",
    "    for key in df.columns:\n",
    "        df[key] = df[key].apply(clean_text)\n",
    "        df[key] = df[key].apply(remove_stopwords)\n",
    "        df[key] = df[key].apply(lemmatizer)\n",
    "        df[key] = df[key].apply(clean_text)\n",
    "        df[key] = df[key].apply(remove_stopwords)\n",
    "    df['text'] = (df['brand'] + ' ' + df['product_full_name'] + ' ' + df['description'] + ' ' + df['brand_category'] + ' ' + df['details']).apply(str)\n",
    "    X = df['text'].values\n",
    "    X = tokenizer.texts_to_sequences(X)\n",
    "    X = pad_sequences(X, maxlen=length, padding='post')\n",
    "    results = model.predict(X)\n",
    "    results_df = pd.DataFrame()\n",
    "    results_mask = results > 0.1\n",
    "    for i in range(len(label_list)):\n",
    "        results_df[label_list[i]] = results_mask[:,i]\n",
    "        results_df[label_list[i]] = results_df[label_list[i]].apply(int)\n",
    "    results_df['sum']  = 0\n",
    "    for key in label_list:\n",
    "        results_df['sum'] = results_df['sum'] + results_df[key]\n",
    "    (results_df['sum'] == 0).sum()\n",
    "    results_df = results_df.drop(columns = ['sum'])\n",
    "    for key in label_list:\n",
    "        results_df[key] = results_df[key].apply(lambda x: key if x == 1 else '')\n",
    "\n",
    "    results_df['attribute_value'] = ''\n",
    "    for key in label_list:\n",
    "        results_df['attribute_value'] = results_df['attribute_value'] + ' ' + results_df[key]\n",
    "\n",
    "    results_df['attribute_value'] = results_df['attribute_value'].apply(lambda x: ', '.join(x.split()))\n",
    "    data['attribute_value'] = results_df['attribute_value']\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pHysGjOuhlea"
   },
   "outputs": [],
   "source": [
    "brand = \"frame\"\n",
    "product_full_name = \"les second medium noir\"\n",
    "description = \"'minimal , modern styling meet refined luxury les second caba tote craft exquisite leather , structured handbag equip adjustable high polish peg buttonhole double drop handle , center welt seam , detachable pouch , frame logo discreetly emboss'\"\n",
    "details = np.nan\n",
    "brand_category = 'accessory'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 114
    },
    "colab_type": "code",
    "id": "Wq_DOyMbhrm4",
    "outputId": "05655641-5bdf-4ec4-d746-dc5d1b62d219"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>product_full_name</th>\n",
       "      <th>description</th>\n",
       "      <th>details</th>\n",
       "      <th>brand_category</th>\n",
       "      <th>attribute_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>frame</td>\n",
       "      <td>les second medium noir</td>\n",
       "      <td>'minimal , modern styling meet refined luxury ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>accessory</td>\n",
       "      <td>accessory, blazerscoatsjackets, onepiece, piec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   brand  ...                                    attribute_value\n",
       "0  frame  ...  accessory, blazerscoatsjackets, onepiece, piec...\n",
       "\n",
       "[1 rows x 6 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_style(brand, product_full_name, description, details, brand_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7DG5qSjShubb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "LSTM_Glove_Category.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
